{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 -qq install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Used just for loading the respective dataset\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/yasserh/housing-prices-dataset\n",
      "License(s): CC0-1.0\n",
      "Downloading housing-prices-dataset.zip to ../data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/4.63k [00:00<?, ?B/s]\n",
      "100%|██████████| 4.63k/4.63k [00:00<00:00, 2.55MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d yasserh/housing-prices-dataset -p ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../data/housing-prices-dataset.zip\n",
      "  inflating: ../data/Housing.csv     \n"
     ]
    }
   ],
   "source": [
    "!unzip ../data/housing-prices-dataset.zip -d ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data using pandas (only for loading)\n",
    "data = pd.read_csv('../data/housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['price', 'area', 'bedrooms', 'stories']]   # As per the requirements of the assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>stories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  stories\n",
       "0  13300000  7420         4        3\n",
       "1  12250000  8960         4        4\n",
       "2  12250000  9960         3        2\n",
       "3  12215000  7500         4        2\n",
       "4  11410000  7420         4        2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13300000, 7420, 4, 3], [12250000, 8960, 4, 4], [12250000, 9960, 3, 2], [12215000, 7500, 4, 2], [11410000, 7420, 4, 2], [10850000, 7500, 3, 1], [10150000, 8580, 4, 4], [10150000, 16200, 5, 2], [9870000, 8100, 4, 2], [9800000, 5750, 3, 4], [9800000, 13200, 3, 2], [9681000, 6000, 4, 2], [9310000, 6550, 4, 2], [9240000, 3500, 4, 2], [9240000, 7800, 3, 2], [9100000, 6000, 4, 2], [9100000, 6600, 4, 2], [8960000, 8500, 3, 4], [8890000, 4600, 3, 2], [8855000, 6420, 3, 2], [8750000, 4320, 3, 2], [8680000, 7155, 3, 1], [8645000, 8050, 3, 1], [8645000, 4560, 3, 2], [8575000, 8800, 3, 2], [8540000, 6540, 4, 2], [8463000, 6000, 3, 4], [8400000, 8875, 3, 1], [8400000, 7950, 5, 2], [8400000, 5500, 4, 2], [8400000, 7475, 3, 4], [8400000, 7000, 3, 4], [8295000, 4880, 4, 2], [8190000, 5960, 3, 2], [8120000, 6840, 5, 2], [8080940, 7000, 3, 4], [8043000, 7482, 3, 3], [7980000, 9000, 4, 4], [7962500, 6000, 3, 4], [7910000, 6000, 4, 4], [7875000, 6550, 3, 2], [7840000, 6360, 3, 4], [7700000, 6480, 3, 4], [7700000, 6000, 4, 4], [7560000, 6000, 4, 4], [7560000, 6000, 3, 3], [7525000, 6000, 3, 4], [7490000, 6600, 3, 4], [7455000, 4300, 3, 2], [7420000, 7440, 3, 1], [7420000, 7440, 3, 4], [7420000, 6325, 3, 4], [7350000, 6000, 4, 4], [7350000, 5150, 3, 4], [7350000, 6000, 3, 2], [7350000, 6000, 3, 2], [7343000, 11440, 4, 2], [7245000, 9000, 4, 4], [7210000, 7680, 4, 4], [7210000, 6000, 3, 4], [7140000, 6000, 3, 2], [7070000, 8880, 2, 1], [7070000, 6240, 4, 2], [7035000, 6360, 4, 3], [7000000, 11175, 3, 1], [6930000, 8880, 3, 2], [6930000, 13200, 2, 1], [6895000, 7700, 3, 1], [6860000, 6000, 3, 1], [6790000, 12090, 4, 2], [6790000, 4000, 3, 2], [6755000, 6000, 4, 4], [6720000, 5020, 3, 4], [6685000, 6600, 2, 4], [6650000, 4040, 3, 2], [6650000, 4260, 4, 2], [6650000, 6420, 3, 3], [6650000, 6500, 3, 3], [6650000, 5700, 3, 1], [6650000, 6000, 3, 3], [6629000, 6000, 3, 2], [6615000, 4000, 3, 2], [6615000, 10500, 3, 1], [6580000, 6000, 3, 4], [6510000, 3760, 3, 2], [6510000, 8250, 3, 3], [6510000, 6670, 3, 3], [6475000, 3960, 3, 1], [6475000, 7410, 3, 1], [6440000, 8580, 5, 2], [6440000, 5000, 3, 2], [6419000, 6750, 2, 1], [6405000, 4800, 3, 4], [6300000, 7200, 3, 1], [6300000, 6000, 4, 4], [6300000, 4100, 3, 3], [6300000, 9000, 3, 1], [6300000, 6400, 3, 1], [6293000, 6600, 3, 3], [6265000, 6000, 4, 3], [6230000, 6600, 3, 1], [6230000, 5500, 3, 3], [6195000, 5500, 3, 4], [6195000, 6350, 3, 3], [6195000, 5500, 3, 1], [6160000, 4500, 3, 4], [6160000, 5450, 4, 1], [6125000, 6420, 3, 3], [6107500, 3240, 4, 3], [6090000, 6615, 4, 2], [6090000, 6600, 3, 1], [6090000, 8372, 3, 3], [6083000, 4300, 6, 2], [6083000, 9620, 3, 1], [6020000, 6800, 2, 1], [6020000, 8000, 3, 1], [6020000, 6900, 3, 1], [5950000, 3700, 4, 2], [5950000, 6420, 3, 1], [5950000, 7020, 3, 1], [5950000, 6540, 3, 1], [5950000, 7231, 3, 2], [5950000, 6254, 4, 1], [5950000, 7320, 4, 2], [5950000, 6525, 3, 4], [5943000, 15600, 3, 1], [5880000, 7160, 3, 1], [5880000, 6500, 3, 3], [5873000, 5500, 3, 3], [5873000, 11460, 3, 3], [5866000, 4800, 3, 1], [5810000, 5828, 4, 4], [5810000, 5200, 3, 3], [5810000, 4800, 3, 3], [5803000, 7000, 3, 1], [5775000, 6000, 3, 4], [5740000, 5400, 4, 2], [5740000, 4640, 4, 2], [5740000, 5000, 3, 3], [5740000, 6360, 3, 1], [5740000, 5800, 3, 4], [5652500, 6660, 4, 2], [5600000, 10500, 4, 2], [5600000, 4800, 5, 3], [5600000, 4700, 4, 2], [5600000, 5000, 3, 4], [5600000, 10500, 2, 1], [5600000, 5500, 3, 2], [5600000, 6360, 3, 3], [5600000, 6600, 4, 1], [5600000, 5136, 3, 2], [5565000, 4400, 4, 2], [5565000, 5400, 5, 2], [5530000, 3300, 3, 2], [5530000, 3650, 3, 2], [5530000, 6100, 3, 1], [5523000, 6900, 3, 1], [5495000, 2817, 4, 2], [5495000, 7980, 3, 1], [5460000, 3150, 3, 1], [5460000, 6210, 4, 4], [5460000, 6100, 3, 3], [5460000, 6600, 4, 2], [5425000, 6825, 3, 1], [5390000, 6710, 3, 2], [5383000, 6450, 3, 1], [5320000, 7800, 3, 1], [5285000, 4600, 2, 1], [5250000, 4260, 4, 2], [5250000, 6540, 4, 2], [5250000, 5500, 3, 1], [5250000, 10269, 3, 1], [5250000, 8400, 3, 2], [5250000, 5300, 4, 1], [5250000, 3800, 3, 2], [5250000, 9800, 4, 2], [5250000, 8520, 3, 1], [5243000, 6050, 3, 1], [5229000, 7085, 3, 1], [5215000, 3180, 3, 2], [5215000, 4500, 4, 1], [5215000, 7200, 3, 2], [5145000, 3410, 3, 2], [5145000, 7980, 3, 1], [5110000, 3000, 3, 2], [5110000, 3000, 3, 2], [5110000, 11410, 2, 2], [5110000, 6100, 3, 1], [5075000, 5720, 2, 2], [5040000, 3540, 2, 1], [5040000, 7600, 4, 2], [5040000, 10700, 3, 2], [5040000, 6600, 3, 1], [5033000, 4800, 2, 1], [5005000, 8150, 3, 1], [4970000, 4410, 4, 2], [4970000, 7686, 3, 1], [4956000, 2800, 3, 2], [4935000, 5948, 3, 2], [4907000, 4200, 3, 2], [4900000, 4520, 3, 2], [4900000, 4095, 3, 2], [4900000, 4120, 2, 1], [4900000, 5400, 4, 2], [4900000, 4770, 3, 1], [4900000, 6300, 3, 1], [4900000, 5800, 2, 1], [4900000, 3000, 3, 2], [4900000, 2970, 3, 3], [4900000, 6720, 3, 1], [4900000, 4646, 3, 2], [4900000, 12900, 3, 1], [4893000, 3420, 4, 2], [4893000, 4995, 4, 1], [4865000, 4350, 2, 1], [4830000, 4160, 3, 3], [4830000, 6040, 3, 1], [4830000, 6862, 3, 2], [4830000, 4815, 2, 1], [4795000, 7000, 3, 2], [4795000, 8100, 4, 4], [4767000, 3420, 4, 2], [4760000, 9166, 2, 1], [4760000, 6321, 3, 2], [4760000, 10240, 2, 1], [4753000, 6440, 2, 1], [4690000, 5170, 3, 4], [4690000, 6000, 2, 1], [4690000, 3630, 3, 2], [4690000, 9667, 4, 2], [4690000, 5400, 2, 2], [4690000, 4320, 3, 1], [4655000, 3745, 3, 2], [4620000, 4160, 3, 1], [4620000, 3880, 3, 2], [4620000, 5680, 3, 2], [4620000, 2870, 2, 2], [4620000, 5010, 3, 2], [4613000, 4510, 4, 2], [4585000, 4000, 3, 2], [4585000, 3840, 3, 2], [4550000, 3760, 3, 1], [4550000, 3640, 3, 2], [4550000, 2550, 3, 2], [4550000, 5320, 3, 2], [4550000, 5360, 3, 2], [4550000, 3520, 3, 1], [4550000, 8400, 4, 4], [4543000, 4100, 2, 1], [4543000, 4990, 4, 2], [4515000, 3510, 3, 3], [4515000, 3450, 3, 2], [4515000, 9860, 3, 1], [4515000, 3520, 2, 2], [4480000, 4510, 4, 2], [4480000, 5885, 2, 1], [4480000, 4000, 3, 2], [4480000, 8250, 3, 1], [4480000, 4040, 3, 2], [4473000, 6360, 2, 1], [4473000, 3162, 3, 2], [4473000, 3510, 3, 2], [4445000, 3750, 2, 1], [4410000, 3968, 3, 2], [4410000, 4900, 2, 2], [4403000, 2880, 3, 2], [4403000, 4880, 3, 1], [4403000, 4920, 3, 2], [4382000, 4950, 4, 2], [4375000, 3900, 3, 2], [4340000, 4500, 3, 3], [4340000, 1905, 5, 2], [4340000, 4075, 3, 1], [4340000, 3500, 4, 2], [4340000, 6450, 4, 2], [4319000, 4032, 2, 1], [4305000, 4400, 2, 1], [4305000, 10360, 2, 1], [4277000, 3400, 3, 2], [4270000, 6360, 2, 1], [4270000, 6360, 2, 2], [4270000, 4500, 2, 1], [4270000, 2175, 3, 2], [4270000, 4360, 4, 2], [4270000, 7770, 2, 1], [4235000, 6650, 3, 2], [4235000, 2787, 3, 1], [4200000, 5500, 3, 2], [4200000, 5040, 3, 2], [4200000, 5850, 2, 1], [4200000, 2610, 4, 2], [4200000, 2953, 3, 2], [4200000, 2747, 4, 2], [4200000, 4410, 2, 1], [4200000, 4000, 4, 2], [4200000, 2325, 3, 2], [4200000, 4600, 3, 2], [4200000, 3640, 3, 2], [4200000, 5800, 3, 1], [4200000, 7000, 3, 1], [4200000, 4079, 3, 3], [4200000, 3520, 3, 2], [4200000, 2145, 3, 3], [4200000, 4500, 3, 1], [4193000, 8250, 3, 1], [4193000, 3450, 3, 2], [4165000, 4840, 3, 2], [4165000, 4080, 3, 2], [4165000, 4046, 3, 2], [4130000, 4632, 4, 2], [4130000, 5985, 3, 1], [4123000, 6060, 2, 1], [4098500, 3600, 3, 1], [4095000, 3680, 3, 2], [4095000, 4040, 2, 2], [4095000, 5600, 2, 1], [4060000, 5900, 4, 2], [4060000, 4992, 3, 2], [4060000, 4340, 3, 1], [4060000, 3000, 4, 3], [4060000, 4320, 3, 2], [4025000, 3630, 3, 2], [4025000, 3460, 3, 1], [4025000, 5400, 3, 1], [4007500, 4500, 3, 2], [4007500, 3460, 4, 2], [3990000, 4100, 4, 1], [3990000, 6480, 3, 2], [3990000, 4500, 3, 2], [3990000, 3960, 3, 2], [3990000, 4050, 2, 2], [3920000, 7260, 3, 1], [3920000, 5500, 4, 2], [3920000, 3000, 3, 2], [3920000, 3290, 2, 1], [3920000, 3816, 2, 1], [3920000, 8080, 3, 1], [3920000, 2145, 4, 1], [3885000, 3780, 2, 2], [3885000, 3180, 4, 2], [3850000, 5300, 5, 2], [3850000, 3180, 2, 1], [3850000, 7152, 3, 2], [3850000, 4080, 2, 1], [3850000, 3850, 2, 1], [3850000, 2015, 3, 2], [3850000, 2176, 2, 2], [3836000, 3350, 3, 2], [3815000, 3150, 2, 1], [3780000, 4820, 3, 2], [3780000, 3420, 2, 2], [3780000, 3600, 2, 1], [3780000, 5830, 2, 1], [3780000, 2856, 3, 3], [3780000, 8400, 2, 1], [3773000, 8250, 3, 1], [3773000, 2520, 5, 1], [3773000, 6930, 4, 2], [3745000, 3480, 2, 1], [3710000, 3600, 3, 1], [3710000, 4040, 2, 1], [3710000, 6020, 3, 1], [3710000, 4050, 2, 1], [3710000, 3584, 2, 1], [3703000, 3120, 3, 2], [3703000, 5450, 2, 1], [3675000, 3630, 2, 1], [3675000, 3630, 2, 1], [3675000, 5640, 2, 1], [3675000, 3600, 2, 1], [3640000, 4280, 2, 1], [3640000, 3570, 3, 2], [3640000, 3180, 3, 2], [3640000, 3000, 2, 2], [3640000, 3520, 2, 1], [3640000, 5960, 3, 2], [3640000, 4130, 3, 2], [3640000, 2850, 3, 2], [3640000, 2275, 3, 3], [3633000, 3520, 3, 1], [3605000, 4500, 2, 1], [3605000, 4000, 2, 1], [3570000, 3150, 3, 2], [3570000, 4500, 4, 2], [3570000, 4500, 2, 1], [3570000, 3640, 2, 1], [3535000, 3850, 3, 1], [3500000, 4240, 3, 2], [3500000, 3650, 3, 2], [3500000, 4600, 4, 2], [3500000, 2135, 3, 2], [3500000, 3036, 3, 2], [3500000, 3990, 3, 2], [3500000, 7424, 3, 1], [3500000, 3480, 3, 1], [3500000, 3600, 6, 2], [3500000, 3640, 2, 1], [3500000, 5900, 2, 1], [3500000, 3120, 3, 2], [3500000, 7350, 2, 1], [3500000, 3512, 2, 1], [3500000, 9500, 3, 2], [3500000, 5880, 2, 1], [3500000, 12944, 3, 1], [3493000, 4900, 3, 2], [3465000, 3060, 3, 1], [3465000, 5320, 2, 1], [3465000, 2145, 3, 3], [3430000, 4000, 2, 1], [3430000, 3185, 2, 1], [3430000, 3850, 3, 1], [3430000, 2145, 3, 3], [3430000, 2610, 3, 2], [3430000, 1950, 3, 2], [3423000, 4040, 2, 1], [3395000, 4785, 3, 2], [3395000, 3450, 3, 1], [3395000, 3640, 2, 1], [3360000, 3500, 4, 2], [3360000, 4960, 4, 3], [3360000, 4120, 2, 2], [3360000, 4750, 2, 1], [3360000, 3720, 2, 1], [3360000, 3750, 3, 1], [3360000, 3100, 3, 2], [3360000, 3185, 2, 1], [3353000, 2700, 3, 1], [3332000, 2145, 3, 2], [3325000, 4040, 2, 1], [3325000, 4775, 4, 2], [3290000, 2500, 2, 1], [3290000, 3180, 4, 2], [3290000, 6060, 3, 1], [3290000, 3480, 4, 2], [3290000, 3792, 4, 2], [3290000, 4040, 2, 1], [3290000, 2145, 3, 2], [3290000, 5880, 3, 1], [3255000, 4500, 2, 1], [3255000, 3930, 2, 1], [3234000, 3640, 4, 2], [3220000, 4370, 3, 2], [3220000, 2684, 2, 1], [3220000, 4320, 3, 1], [3220000, 3120, 3, 2], [3150000, 3450, 1, 1], [3150000, 3986, 2, 1], [3150000, 3500, 2, 1], [3150000, 4095, 2, 1], [3150000, 1650, 3, 2], [3150000, 3450, 3, 2], [3150000, 6750, 2, 1], [3150000, 9000, 3, 2], [3150000, 3069, 2, 1], [3143000, 4500, 3, 2], [3129000, 5495, 3, 1], [3118850, 2398, 3, 1], [3115000, 3000, 3, 1], [3115000, 3850, 3, 2], [3115000, 3500, 2, 1], [3087000, 8100, 2, 1], [3080000, 4960, 2, 1], [3080000, 2160, 3, 2], [3080000, 3090, 2, 1], [3080000, 4500, 2, 2], [3045000, 3800, 2, 1], [3010000, 3090, 3, 2], [3010000, 3240, 3, 2], [3010000, 2835, 2, 1], [3010000, 4600, 2, 1], [3010000, 5076, 3, 1], [3010000, 3750, 3, 2], [3010000, 3630, 4, 2], [3003000, 8050, 2, 1], [2975000, 4352, 4, 2], [2961000, 3000, 2, 2], [2940000, 5850, 3, 2], [2940000, 4960, 2, 1], [2940000, 3600, 3, 2], [2940000, 3660, 4, 2], [2940000, 3480, 3, 2], [2940000, 2700, 2, 1], [2940000, 3150, 3, 2], [2940000, 6615, 3, 2], [2870000, 3040, 2, 1], [2870000, 3630, 2, 1], [2870000, 6000, 2, 1], [2870000, 5400, 4, 2], [2852500, 5200, 4, 3], [2835000, 3300, 3, 2], [2835000, 4350, 3, 2], [2835000, 2640, 2, 1], [2800000, 2650, 3, 2], [2800000, 3960, 3, 1], [2730000, 6800, 2, 1], [2730000, 4000, 3, 2], [2695000, 4000, 2, 1], [2660000, 3934, 2, 1], [2660000, 2000, 2, 2], [2660000, 3630, 3, 2], [2660000, 2800, 3, 1], [2660000, 2430, 3, 1], [2660000, 3480, 2, 1], [2660000, 4000, 3, 1], [2653000, 3185, 2, 1], [2653000, 4000, 3, 2], [2604000, 2910, 2, 1], [2590000, 3600, 2, 1], [2590000, 4400, 2, 1], [2590000, 3600, 2, 2], [2520000, 2880, 3, 1], [2520000, 3180, 3, 1], [2520000, 3000, 2, 2], [2485000, 4400, 3, 2], [2485000, 3000, 3, 2], [2450000, 3210, 3, 2], [2450000, 3240, 2, 1], [2450000, 3000, 2, 1], [2450000, 3500, 2, 1], [2450000, 4840, 2, 2], [2450000, 7700, 2, 1], [2408000, 3635, 2, 1], [2380000, 2475, 3, 2], [2380000, 2787, 4, 2], [2380000, 3264, 2, 1], [2345000, 3640, 2, 1], [2310000, 3180, 2, 1], [2275000, 1836, 2, 1], [2275000, 3970, 1, 1], [2275000, 3970, 3, 2], [2240000, 1950, 3, 1], [2233000, 5300, 3, 1], [2135000, 3000, 2, 1], [2100000, 2400, 3, 2], [2100000, 3000, 4, 2], [2100000, 3360, 2, 1], [1960000, 3420, 5, 2], [1890000, 1700, 3, 2], [1890000, 3649, 2, 1], [1855000, 2990, 2, 1], [1820000, 3000, 2, 1], [1767150, 2400, 3, 1], [1750000, 3620, 2, 1], [1750000, 2910, 3, 1], [1750000, 3850, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(data) # For, testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function: Normalizing features to prevent large multiplications\n",
    "def normalize(data):\n",
    "    max_vals = [max(col) for col in zip(*data)]\n",
    "    \n",
    "    return [[x / max_val if max_val != 0 else x for x, max_val in zip(row, max_vals)] for row in data]\n",
    "\n",
    "# def normalize(data):\n",
    "#     # Converting all data to floats\n",
    "#     data = [[float(x) for x in row] for row in data]\n",
    "    \n",
    "#     max_vals = [max(col) for col in zip(*data)]\n",
    "    \n",
    "#     return [[x / max_val if max_val != 0 else x for x, max_val in zip(row, max_vals)] for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and normalized dataset with shape: 545, 4\n"
     ]
    }
   ],
   "source": [
    "data = normalize(data)\n",
    "\n",
    "print(f\"Loaded and normalized dataset with shape: {len(data)}, {len(data[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Random) Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 381, Test set size: 164\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset into training (80%) and test (20%)\n",
    "random.shuffle(data)\n",
    "split_index = int(0.7 * len(data))\n",
    "train_data = data[:split_index]\n",
    "test_data = data[split_index:]\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}, Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3526315789473684, 0.22407407407407406, 0.5, 0.5], [0.22631578947368422, 0.31333333333333335, 0.5, 0.25], [0.30526315789473685, 0.30814814814814817, 0.5, 0.5], [0.3868421052631579, 0.4925925925925926, 0.5, 0.25], [0.3368421052631579, 0.24938271604938272, 0.5, 0.5]]\n",
      "[[0.22894736842105262, 0.2345679012345679, 0.3333333333333333, 0.25], [0.23421052631578948, 0.18518518518518517, 0.5, 0.25], [0.25263157894736843, 0.23148148148148148, 0.5, 0.25], [0.23157894736842105, 0.2777777777777778, 0.3333333333333333, 0.5], [0.3157894736842105, 0.3611111111111111, 0.3333333333333333, 0.25]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[:5]) # For testing\n",
    "print(test_data[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNetwork:\n",
    "\n",
    "    def __init__(self, parameters, learning_rate, iterations):\n",
    "        self.parameters = parameters  # List of 8 parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def multiply_forward(self, a, b):\n",
    "        return a * b\n",
    "\n",
    "    def multiply_backward(self, upper_derivative_output, a, b):\n",
    "        return upper_derivative_output * b, upper_derivative_output * a\n",
    "\n",
    "    def add_forward(self, a, b):\n",
    "        return a + b\n",
    "\n",
    "    def add_backward(self, upper_derivative_output):\n",
    "        return upper_derivative_output, upper_derivative_output\n",
    "\n",
    "    def max_forward(self, a, b):\n",
    "        return a if a > b else b\n",
    "\n",
    "    def max_backward(self, upper_derivative_output, a, b):\n",
    "        return (upper_derivative_output if a > b else 0), (upper_derivative_output if b > a else 0)\n",
    "\n",
    "    def relu_forward(self, x):\n",
    "        return self.max_forward(0, x)\n",
    "\n",
    "    def relu_backward(self, upper_derivative_output, x):\n",
    "        # Only the gradient corresponding to the active neuron flows back (the first one)\n",
    "        return self.max_backward(upper_derivative_output, x, 0)[0]\n",
    "\n",
    "    def sigmoid_forward(self, x):\n",
    "        if x > 500:\n",
    "            return 1.0\n",
    "        elif x < -500:\n",
    "            return 0.0\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "\n",
    "    def sigmoid_backward(self, upper_derivative_output, activated_sigmoid):\n",
    "        return upper_derivative_output * activated_sigmoid * (1 - activated_sigmoid)\n",
    "\n",
    "    def affine_forward(self, area, bedrooms, stories):\n",
    "        # Computing weighted sum for ReLU branch\n",
    "        weighted_sum_relu = self.add_forward(   # With the parameters[8] as bias term\n",
    "            self.add_forward(\n",
    "                self.add_forward(\n",
    "                    self.multiply_forward(area, self.parameters[0]),\n",
    "                    self.multiply_forward(bedrooms, self.parameters[1])\n",
    "                ),\n",
    "                self.multiply_forward(stories, self.parameters[2])\n",
    "            ),\n",
    "            self.parameters[8]  # Bias term\n",
    "        )\n",
    "        activated_relu = self.relu_forward(weighted_sum_relu)\n",
    "\n",
    "        # Computing weighted sum for Sigmoid branch\n",
    "        weighted_sum_sigmoid = self.add_forward(\n",
    "            self.add_forward(\n",
    "                self.add_forward(\n",
    "                    self.multiply_forward(area, self.parameters[3]),\n",
    "                    self.multiply_forward(bedrooms, self.parameters[4])\n",
    "                ),\n",
    "                self.multiply_forward(stories, self.parameters[5])\n",
    "            ),\n",
    "            self.parameters[8]  # Bias term\n",
    "        )\n",
    "        activated_sigmoid = self.sigmoid_forward(weighted_sum_sigmoid)\n",
    "\n",
    "        # Combining contributions from both branches\n",
    "        relu_contribution = self.multiply_forward(self.parameters[6], activated_relu)\n",
    "        sigmoid_contribution = self.multiply_forward(self.parameters[7], activated_sigmoid)\n",
    "        \n",
    "        predicted_price = self.add_forward(relu_contribution, sigmoid_contribution)\n",
    "\n",
    "        return predicted_price, activated_relu, activated_sigmoid, weighted_sum_relu, weighted_sum_sigmoid\n",
    "\n",
    "    def affine_backward(self, area, bedrooms, stories, actual_price,\n",
    "                        activated_relu, activated_sigmoid,\n",
    "                        weighted_sum_relu, weighted_sum_sigmoid):\n",
    "        grads = [0] * 9\n",
    "        \n",
    "        # Computing the error (difference between prediction and actual price)\n",
    "        # error = predicted_price - actual_price\n",
    "        error = (self.parameters[6] * activated_relu + self.parameters[7] * activated_sigmoid) - actual_price\n",
    "\n",
    "        # ud_1, ud_2 = self.add_backward(error)\n",
    "\n",
    "        # ud_3, ud_4 = self.multiply_backward(ud_1, activated_relu, self.parameters[6])\n",
    "        # ud_5, ud_6 = self.multiply_backward(ud_2, activated_sigmoid, self.parameters[7])\n",
    "\n",
    "        # # Backpropagate through the ReLU and Sigmoid branches\n",
    "        # upper_derivative_wrt_relu = self.relu_backward(ud_3, activated_relu)\n",
    "        # upper_derivative_wrt_sigmoid = self.sigmoid_backward(ud_5, activated_sigmoid)\n",
    "\n",
    "        upper_derivative_wrt_relu = self.relu_backward(error, weighted_sum_relu)\n",
    "        upper_derivative_wrt_sigmoid = self.sigmoid_backward(error, weighted_sum_sigmoid)\n",
    "\n",
    "        # Compute gradients for the weights of the ReLU branch\n",
    "        grads[0], _ = self.multiply_backward(upper_derivative_wrt_relu, area, self.parameters[0])\n",
    "        grads[1], _ = self.multiply_backward(upper_derivative_wrt_relu, bedrooms, self.parameters[1])\n",
    "        grads[2], _ = self.multiply_backward(upper_derivative_wrt_relu, stories, self.parameters[2])\n",
    "\n",
    "        # Compute gradients for the weights of the Sigmoid branch\n",
    "        grads[3], _ = self.multiply_backward(upper_derivative_wrt_sigmoid, area, self.parameters[3])\n",
    "        grads[4], _ = self.multiply_backward(upper_derivative_wrt_sigmoid, bedrooms, self.parameters[4])\n",
    "        grads[5], _ = self.multiply_backward(upper_derivative_wrt_sigmoid, stories, self.parameters[5])\n",
    "\n",
    "        # Gradients for the contributions from ReLU and Sigmoid activations\n",
    "        grads[6] = self.multiply_backward(upper_derivative_wrt_relu, self.parameters[6], activated_relu)[0]\n",
    "        grads[7] = self.multiply_backward(upper_derivative_wrt_sigmoid, self.parameters[7], activated_sigmoid)[0]\n",
    "\n",
    "        # Gradient for the bias term (shared by both branches)\n",
    "        bias_grad_relu, _ = self.add_backward(upper_derivative_wrt_relu)\n",
    "        bias_grad_sigmoid, _ = self.add_backward(upper_derivative_wrt_sigmoid)\n",
    "        grads[8] = bias_grad_relu + bias_grad_sigmoid\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def compute_loss(self, data):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for actual_price, area, bedrooms, stories in data:\n",
    "            predicted_price, _, _, _, _ = self.affine_forward(area, bedrooms, stories)\n",
    "            error = predicted_price - actual_price\n",
    "            total_loss += error ** 2\n",
    "        \n",
    "        return total_loss / len(data)\n",
    "\n",
    "    def compute_gradients(self, data):\n",
    "        grads = [0] * len(self.parameters)\n",
    "        \n",
    "        for actual_price, area, bedrooms, stories in data:\n",
    "            _, activated_relu, activated_sigmoid, weighted_sum_relu, weighted_sum_sigmoid = self.affine_forward(area, bedrooms, stories)\n",
    "            sample_grads = self.affine_backward(area, bedrooms, stories, actual_price,\n",
    "                                                activated_relu, activated_sigmoid,\n",
    "                                                weighted_sum_relu, weighted_sum_sigmoid)\n",
    "            for i in range(len(self.parameters)):\n",
    "                grads[i] += sample_grads[i]\n",
    "        \n",
    "        return [g / len(data) for g in grads]\n",
    "\n",
    "    def train(self, train_data, test_data):\n",
    "        print(f\"Starting training with {len(train_data)} samples...\")\n",
    "\n",
    "        for i in tqdm_notebook(range(self.iterations)):\n",
    "            grads = self.compute_gradients(train_data)\n",
    "\n",
    "            # Updating parameters using gradient descent\n",
    "            for j in range(len(self.parameters)):\n",
    "                self.parameters[j] -= self.learning_rate * grads[j]\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                train_loss = self.compute_loss(train_data)\n",
    "                test_loss = self.compute_loss(test_data)\n",
    "                print(f\"Iteration {i}: Train Loss = {train_loss}, Test Loss = {test_loss}\")\n",
    "\n",
    "        print(\"\\nTraining completed.\")\n",
    "        \n",
    "        final_test_loss = self.compute_loss(test_data)\n",
    "        \n",
    "        print(f\"\\nFinal Test Loss: {final_test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing small random parameters\n",
    "random.seed(42)\n",
    "\n",
    "parameters = [random.uniform(-0.1, 0.1) for _ in range(9)]  # 8+1 for bias term\n",
    "\n",
    "# print(parameters) # For, testing\n",
    "\n",
    "learning_rate = 0.01\n",
    "iterations = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with 381 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18272\\507640581.py:146: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(self.iterations)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d87f771c384db2981014ff6a81bac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Train Loss = 0.18310447167255936, Test Loss = 0.17149833198396594\n",
      "Iteration 100: Train Loss = 0.1825727410327287, Test Loss = 0.17098011913268316\n",
      "Iteration 200: Train Loss = 0.18177951604482545, Test Loss = 0.17020710131093056\n",
      "Iteration 300: Train Loss = 0.18059888834892954, Test Loss = 0.16905664238516224\n",
      "Iteration 400: Train Loss = 0.17884996124923627, Test Loss = 0.1673526119959312\n",
      "Iteration 500: Train Loss = 0.17627990930672016, Test Loss = 0.16484901199843494\n",
      "Iteration 600: Train Loss = 0.16803664468950125, Test Loss = 0.15696477496374875\n",
      "Iteration 700: Train Loss = 0.1032398611275021, Test Loss = 0.09436760265171233\n",
      "Iteration 800: Train Loss = 0.04183718743360201, Test Loss = 0.03596775025556542\n",
      "Iteration 900: Train Loss = 0.025429286964271307, Test Loss = 0.021131222777521257\n",
      "Iteration 1000: Train Loss = 0.02295255310941273, Test Loss = 0.019242053369103198\n",
      "Iteration 1100: Train Loss = 0.022651780143451136, Test Loss = 0.01914461488473045\n",
      "Iteration 1200: Train Loss = 0.022621912237533886, Test Loss = 0.019183712636943698\n",
      "Iteration 1300: Train Loss = 0.022622059434855932, Test Loss = 0.019206870284347106\n",
      "Iteration 1400: Train Loss = 0.022624961275903292, Test Loss = 0.019217146680138273\n",
      "\n",
      "Training completed.\n",
      "\n",
      "Final Test Loss: 0.019222173484710184\n"
     ]
    }
   ],
   "source": [
    "nn = SimpleNeuralNetwork(parameters, learning_rate, iterations)\n",
    "\n",
    "nn.train(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Flowgraph Based Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_f(a, b):\n",
    "    return a * b, b, a  # returns (a*b, d(a*b)/da = b, d(a*b)/db = a)\n",
    "\n",
    "def add_f(a, b):\n",
    "    return a + b, 1, 1  # ∂(a+b)/∂a = 1, ∂(a+b)/∂b = 1\n",
    "\n",
    "def max_f(x, y):\n",
    "    if x >= y:\n",
    "        return x, 1, 0  # derivative: 1 w.r.t. first input, 0 w.r.t. second\n",
    "    else:\n",
    "        return y, 0, 1\n",
    "\n",
    "def multiply_b(d_out, local_a, local_b):\n",
    "    d_a = d_out * local_a  # dL/da = upstream_grad * (∂(a*b)/∂a)\n",
    "    d_b = d_out * local_b  # dL/db = upstream_grad * (∂(a*b)/∂b)\n",
    "\n",
    "    return d_a, d_b\n",
    "\n",
    "def add_b(d_out, local_a, local_b):\n",
    "    return d_out * local_a, d_out * local_b\n",
    "\n",
    "\n",
    "def max_b(d_out, local_first, local_second):\n",
    "    return d_out * local_first, d_out * local_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_nn(P, data):\n",
    "    total_loss = 0\n",
    "    gradients = [0] * 8  # gradients for P[0]...P[7]\n",
    "    \n",
    "    for Y, x, y, z in train_data:\n",
    "        # # Forward Pass\n",
    "        # ReLU branch\n",
    "        o1, ldo1x, ldo1p0 = multiply_f(x, P[0])    # o1 = x * P[0]\n",
    "        o2, ldo2y, ldo2p1 = multiply_f(y, P[1])       # o2 = y * P[1]\n",
    "        o3, ldo3z, ldo3p2 = multiply_f(z, P[2])       # o3 = z * P[2]\n",
    "        \n",
    "        o4, ldo4o1, ldo4o2 = add_f(o1, o2)            # o4 = o1 + o2\n",
    "        o5, ldo5o4, ldo5o3 = add_f(o4, o3)            # o5 = o4 + o3\n",
    "        \n",
    "        # ReLU forward\n",
    "        o6, ldo60, ldo6o5 = max_f(0, o5)              # o6 = max(0, o5)\n",
    "        o7, ldo7o6, ldo7p6 = multiply_f(o6, P[6])      # o7 = o6 * P[6]\n",
    "        \n",
    "        # Sigmoid branch\n",
    "        o8, ldo8x, ldo8p3 = multiply_f(x, P[3])       # o8 = x * P[3]\n",
    "        o9, ldo9y, ldo9p4 = multiply_f(y, P[4])       # o9 = y * P[4]\n",
    "        o10, ldo10z, ldo10p5 = multiply_f(z, P[5])     # o10 = z * P[5]\n",
    "        \n",
    "        o11, ldo11o8, ldo11o9 = add_f(o8, o9)         # o11 = o8 + o9\n",
    "        o12, ldo12o11, ldo12o10 = add_f(o11, o10)      # o12 = o11 + o10\n",
    "        \n",
    "        # Sigmoid forward\n",
    "        sigmoid = 1/(1 + math.exp(-o12))\n",
    "        sd = sigmoid * (1 - sigmoid)  # Derivative of the sigmoid\n",
    "        \n",
    "        o13, ldo13sigmoid, ldo13p7 = multiply_f(sigmoid, P[7])  # o13 = sigmoid * P[7]\n",
    "        \n",
    "        # Final output: add ReLU branch (o7) and Sigmoid branch (o13)\n",
    "        o14, ldo14o7, ldo14o13 = add_f(o7, o13)\n",
    "        \n",
    "        # Compute squared error loss: L = (o14 - Y)^2\n",
    "        loss = (o14 - Y) ** 2\n",
    "        total_loss += loss\n",
    "        \n",
    "        # # Backward Pass \n",
    "        # Starting from the loss: dL/do14 = 2*(o14 - Y)\n",
    "        d_o14 = 2 * (o14 - Y)\n",
    "        \n",
    "        # Backprop through final addition: o14 = o7 + o13\n",
    "        grad_o7, grad_o13 = add_b(d_o14, ldo14o7, ldo14o13)\n",
    "        \n",
    "        # # ReLU Branch Backward\n",
    "        # o7 = o6 * P[6]\n",
    "        grad_o6, grad_P6 = multiply_b(grad_o7, ldo7o6, ldo7p6)\n",
    "        gradients[6] += grad_P6\n",
    "        \n",
    "        # o6 = max(0, o5)\n",
    "        # (We ignore the gradient flowing to the constant 0 input)\n",
    "        _, grad_o5 = max_b(grad_o6, ldo60, ldo6o5)\n",
    "        \n",
    "        # o5 = o4 + o3\n",
    "        grad_o4, grad_o3 = add_b(grad_o5, ldo5o4, ldo5o3)\n",
    "        \n",
    "        # o4 = o1 + o2\n",
    "        grad_o1, grad_o2 = add_b(grad_o4, ldo4o1, ldo4o2)\n",
    "        \n",
    "        # o1 = x * P[0]\n",
    "        _, grad_P0 = multiply_b(grad_o1, ldo1x, ldo1p0)\n",
    "        gradients[0] += grad_P0\n",
    "        \n",
    "        # o2 = y * P[1]\n",
    "        _, grad_P1 = multiply_b(grad_o2, ldo2y, ldo2p1)\n",
    "        gradients[1] += grad_P1\n",
    "        \n",
    "        # o3 = z * P[2]\n",
    "        _, grad_P2 = multiply_b(grad_o3, ldo3z, ldo3p2)\n",
    "        gradients[2] += grad_P2\n",
    "        \n",
    "        # # Sigmoid Branch Backward \n",
    "        # o13 = sigmoid * P[7]\n",
    "        grad_sigmoid, grad_P7 = multiply_b(grad_o13, ldo13sigmoid, ldo13p7)\n",
    "        gradients[7] += grad_P7\n",
    "        \n",
    "        # Backprop through the sigmoid nonlinearity:\n",
    "        # d(sigmoid)/d(o12) = sigmoid*(1 - sigmoid) = sd\n",
    "        grad_o12 = grad_sigmoid * sd\n",
    "        \n",
    "        # o12 = o11 + o10\n",
    "        grad_o11, grad_o10 = add_b(grad_o12, ldo12o11, ldo12o10)\n",
    "        \n",
    "        # o11 = o8 + o9\n",
    "        grad_o8, grad_o9 = add_b(grad_o11, ldo11o8, ldo11o9)\n",
    "        \n",
    "        # o8 = x * P[3]\n",
    "        _, grad_P3 = multiply_b(grad_o8, ldo8x, ldo8p3)\n",
    "        gradients[3] += grad_P3\n",
    "        \n",
    "        # o9 = y * P[4]\n",
    "        _, grad_P4 = multiply_b(grad_o9, ldo9y, ldo9p4)\n",
    "        gradients[4] += grad_P4\n",
    "        \n",
    "        # o10 = z * P[5]\n",
    "        _, grad_P5 = multiply_b(grad_o10, ldo10z, ldo10p5)\n",
    "        gradients[5] += grad_P5\n",
    "\n",
    "    # Averaging loss and gradients over the dataset\n",
    "    avg_loss = total_loss / len(data)\n",
    "    gradients = [g / len(data) for g in gradients]\n",
    "    \n",
    "    return avg_loss, gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "patience = 5\n",
    "best_loss = float('inf')\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "parameters = [random.uniform(-0.1, 0.1) for _ in range(8)]\n",
    "\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18272\\4166612991.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for epoch in tqdm_notebook(range(epochs)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9d05dd5539469daed60c16df5d544a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.140343\n",
      "Epoch 1: Loss = 0.139124\n",
      "Epoch 2: Loss = 0.137918\n",
      "Epoch 3: Loss = 0.136723\n",
      "Epoch 4: Loss = 0.135541\n",
      "Epoch 5: Loss = 0.134371\n",
      "Epoch 6: Loss = 0.133212\n",
      "Epoch 7: Loss = 0.132066\n",
      "Epoch 8: Loss = 0.130930\n",
      "Epoch 9: Loss = 0.129807\n",
      "Epoch 10: Loss = 0.128694\n",
      "Epoch 11: Loss = 0.127593\n",
      "Epoch 12: Loss = 0.126502\n",
      "Epoch 13: Loss = 0.125423\n",
      "Epoch 14: Loss = 0.124355\n",
      "\n",
      "Training completed.\n",
      "\n",
      "Optimized Parameters: [0.02788535969157674, -0.09499784895546662, -0.04499413632617615, -0.055417287176487626, 0.04720255751880011, 0.03525772714941775, 0.0784359135409691, 0.08162299857179622]\n",
      "Final Loss: 0.124355\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm_notebook(range(epochs)):\n",
    "    loss, grads = simple_nn(parameters, train_data)\n",
    "    \n",
    "    # Updating parameters\n",
    "    for i in range(len(parameters)):\n",
    "        parameters[i] -= learning_rate * grads[i]\n",
    "    \n",
    "    # Early stopping check\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "    \n",
    "        break\n",
    "        \n",
    "    print(f\"Epoch {epoch}: Loss = {loss:.6f}\")\n",
    "\n",
    "print(\"\\nTraining completed.\")\n",
    "print(\"\\nOptimized Parameters:\", parameters)\n",
    "print(f\"Final Loss: {loss:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
